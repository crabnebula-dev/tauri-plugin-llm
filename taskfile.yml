version: "3"

env:
  CONTAINER_RUNTIME: container
  CONTAINER_IMAGE_TAG: container-tauri-plugin-llm

tasks:
  default:
    silent: true
    desc: Shows all available tasks
    cmds:
      - task --list-all

  build_container:
    silent: true
    desc: Builds the container for Tauri tests
    cmds:
      - container build -f End2End.dockerfile -t $CONTAINER_IMAGE_TAG .

  container:
    silent: true
    desc: Debugging task to enter the container
    cmds:
      - $CONTAINER_RUNTIME run -ti --rm -v $(pwd):/testing --cpus 8 -m 16G $CONTAINER_IMAGE_TAG bash

  fetch_llama3.2_instruct:
    silent: true
    desc: Downloads meta-llama/Llama-3.2-3B-Instruct via HF API in container
    cmds:
      - task: fetch
        vars: { MODEL: "meta-llama/Llama-3.2-3B-Instruct" }
        
  fetch_qwen3_4b_instruct:
    silent: true
    desc: Downloads Qwen/Qwen3-4B-Instruct-2507 via HF API in container
    cmds:
      - task: fetch
        vars: { MODEL: "Qwen/Qwen3-4B-Instruct-2507" }

  fetch_gemma_3_4b_it:
    silent: true
    desc: Downloads 'google/gemma-3-4b-it' via HF API in container
    cmds:
      - task: fetch
        vars: { MODEL: "google/gemma-3-1b-it" }

  fetch:
    silent: true
    desc: Downloads a model via HF API in container. Requires HF token!
    requires:
      vars: [MODEL]
    vars:
      HF_TOKEN:
        sh: '[ "$(uname)" = "Darwin" ] && security find-generic-password -a "huggingface-token" -w || echo ""'
    cmds:
      - echo "Downloading {{.MODEL}}"
      - $CONTAINER_RUNTIME run -ti --rm -v $(pwd)/models:/models --env HF_TOKEN="{{.HF_TOKEN}}" --cpus 8 -m 16G $CONTAINER_IMAGE_TAG bash -c "hf download --cache-dir /models {{.MODEL}}" 

  tests:
    silent: true
    desc: Runs all end to end tests
    cmds:
      - cargo test --all
      - $CONTAINER_RUNTIME run -ti --rm -v $(pwd):/testing --cpus 8 -m 16G $CONTAINER_IMAGE_TAG task 'run_tests'

  run_tests:
    silent: true
    desc: (CONTAINER) Execute End to End Tests
    dir: /testing/examples/tauri-app/test/specs
    env:
      DISPLAY: 0
      RUST_LOG: tauri_plugin_llm=trace
    cmds:
      - xvfb-run --auto-servernum --server-args='-screen 0 1280x720x24' bash -c 'pnpm install --force; pnpm test'
  